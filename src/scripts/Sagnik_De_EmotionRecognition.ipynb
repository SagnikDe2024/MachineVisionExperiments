{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5131c578ea1b14d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sagnik De\n",
    "Email : sagnik4de@gmail.com\n",
    "Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fee5a679fba44a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T03:56:45.134631900Z",
     "start_time": "2024-03-18T03:56:45.095822500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# \n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/EmotionRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619bc98f5fde2f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "These are the dependencies. Running them will automatically install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9fdd78730bce08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T03:56:50.782682200Z",
     "start_time": "2024-03-18T03:56:45.138751600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (0.0.86)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (2.2.1)\n",
      "Requirement already satisfied: gdown>=3.10.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (5.1.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (4.66.2)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (10.2.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (4.9.0.80)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (2.16.1)\n",
      "Requirement already satisfied: keras>=2.2.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (3.0.5)\n",
      "Requirement already satisfied: Flask>=1.1.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (3.0.2)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (0.1.1)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (0.0.14)\n",
      "Requirement already satisfied: fire>=0.4.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (0.6.0)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from deepface) (21.2.0)\n",
      "Requirement already satisfied: six in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from fire>=0.4.0->deepface) (2.4.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Flask>=1.1.2->deepface) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Flask>=1.1.2->deepface) (1.7.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from gdown>=3.10.1->deepface) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from gdown>=3.10.1->deepface) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from gunicorn>=20.1.0->deepface) (24.0)\n",
      "Requirement already satisfied: absl-py in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (3.10.0)\n",
      "Requirement already satisfied: dm-tree in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (0.1.8)\n",
      "Requirement already satisfied: ml-dtypes in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from keras>=2.2.0->deepface) (0.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow>=1.9.0->deepface) (2.16.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.31.0)\n",
      "Requirement already satisfied: colorama in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tqdm>=4.30.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from rich->keras>=2.2.0->deepface) (2.17.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.41.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (8.1.29)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (3.8.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.0)\n",
      "Requirement already satisfied: colorama in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\mywork\\ml\\deepfaceandemotion\\venv\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e252c135e1cef260",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is for showing the image with the bounding boxes with the emotions detected. This will also the return the modified image so that it can be save in the target directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e8711979e3cc20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T03:56:50.783693200Z",
     "start_time": "2024-03-18T03:56:50.774529400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "\n",
    "def show_bbox_with_emotion(image: Image, bboxes: dict, do_show=True):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    fnt = ImageFont.truetype(\"../../deepfaceAndEmotion/GlacialIndifference-Regular.otf\", 12)\n",
    "    for bbox in bboxes:\n",
    "        x1 = int(bbox['x1'])\n",
    "        y1 = int(bbox['y1'])\n",
    "        x2 = int(bbox['x2'])\n",
    "        y2 = int(bbox['y2'])\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0, 85), width=1)\n",
    "        emotion = f\"{bbox['f_i']}_{bbox['emotion']}\"\n",
    "        draw.text((x1, y1), emotion, font=fnt, fill=(255, 0, 0))\n",
    "    if do_show:\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba4684a701e6f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The function below is used to acquire the emotion of the face defined by the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc6b01aed475fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T03:56:50.784692700Z",
     "start_time": "2024-03-18T03:56:50.779011100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "def get_emotion(cropped_face):\n",
    "    analyzed_emotion = DeepFace.analyze(cropped_face, actions=['emotion'], enforce_detection=False)[0]\n",
    "    return {'emotion': analyzed_emotion['dominant_emotion'],\n",
    "            'emo_confidence': analyzed_emotion['face_confidence']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780f415ec75fafc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So we want to use the Yolo library and dump the folder with all the images so that processing can be done all in bulk fashion. Here I am returning a dataframe of the inferred results. That can be saved as csv for later analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f469e70be38cf078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T03:56:50.826157Z",
     "start_time": "2024-03-18T03:56:50.784692700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-face.pt')\n",
    "\n",
    "\n",
    "def detect_face(path_to_images, path_to_results, limit):\n",
    "    inference_results = []\n",
    "    inferences = model(path_to_images,stream=True)\n",
    "    for image_number, inference in enumerate(inferences):\n",
    "        if 0 < limit <= image_number:\n",
    "            break\n",
    "        image_path = inference.path\n",
    "        for i, detected_face in enumerate(inference):\n",
    "            given_xyxy = detected_face.boxes.xyxy[0]\n",
    "            x1 = int(given_xyxy[0].item())\n",
    "            y1 = int(given_xyxy[1].item())\n",
    "            x2 = int(given_xyxy[2].item())\n",
    "            y2 = int(given_xyxy[3].item())\n",
    "            h, w = inference.orig_shape\n",
    "            face_box = inference.orig_img[y1:y2, x1:x2]\n",
    "            emotional_resp = get_emotion(face_box)\n",
    "            common_file_data = {'image_path': image_path, 'h': h, 'w': w, 'f_i': i}\n",
    "            xys = {'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2}\n",
    "            all_facial_results = {**common_file_data, **xys, **emotional_resp}\n",
    "            inference_results.append(all_facial_results)\n",
    "    df = pd.DataFrame(inference_results)\n",
    "    if path_to_results is not None:\n",
    "        df.to_csv(path_to_results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247250ef2c87a9e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Store generated images with bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9f07d028345c5b4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T04:53:44.436350600Z",
     "start_time": "2024-03-18T04:53:44.422148600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def store_with_bounding_box(csv_loc, target_location):\n",
    "    df = pd.read_csv(csv_loc)\n",
    "    file_paths = df['image_path'].unique()\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f'Generating bounding box for {file_name} and saving it to {target_location}')\n",
    "        filtered = df[df['image_path'].str.contains(file_name)]\n",
    "        list_faces = list(filtered.T.to_dict().values())\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "        show_bbox_with_emotion(image, list_faces, do_show=False)\n",
    "        png_name = file_name.replace('.jpg', '.png')\n",
    "        location = os.path.join(target_location, png_name)\n",
    "        image.save(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f5a06b3c4e841",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The first 100 images will be inferred with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aae7ba02088e6696",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T04:56:27.686023800Z",
     "start_time": "2024-03-18T04:53:47.151721300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\001333d5a0464e2fb454647fb3cf1dce.jpg: 416x640 11 faces, 64.4ms\n",
      "image 2/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\00746310ec034c5484f3b998cbfa4795.jpg: 640x640 4 faces, 83.1ms\n",
      "image 3/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\014a05e9ae584321a9f473c994dd9818.jpg: 480x640 2 faces, 62.2ms\n",
      "image 4/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0150b34a95e04a2c8d588af9942aec2d.jpg: 544x640 4 faces, 86.2ms\n",
      "image 5/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\01537a90201f483c8492876384636764.jpg: 544x640 56 faces, 63.3ms\n",
      "image 6/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\022915fab0af4d5dbc74c88214a21ee5.jpg: 384x640 6 faces, 58.7ms\n",
      "image 7/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0272a05589274fedaa11b1c4a439287a.jpg: 544x640 9 faces, 166.0ms\n",
      "image 8/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0275f9a215934751b2b477d509cf3491.jpg: 448x640 9 faces, 59.9ms\n",
      "image 9/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\02a9ea1d381743e99e9e0eb95e746767.jpg: 448x640 7 faces, 61.7ms\n",
      "image 10/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\02cc9d2429424b3b81113f14b5a69ad9.jpg: 480x640 12 faces, 64.1ms\n",
      "image 11/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\03e3f6e435b84a9e94a4c8d3ab00a498.jpg: 384x640 4 faces, 76.3ms\n",
      "image 12/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0437912fa55c4fdeab4d167eb28231a3.jpg: 480x640 13 faces, 72.5ms\n",
      "image 13/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\04a77bfe71c644409ef4893854f4a1d7.jpg: 448x640 14 faces, 85.7ms\n",
      "image 14/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\04b74dac85904092b57a1384998da221.jpg: 384x640 3 faces, 68.6ms\n",
      "image 15/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0503afe5d1b14b7daebd0847996e8085.jpg: 480x640 45 faces, 82.9ms\n",
      "image 16/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\050adf2c7c104267a42d8b30b8a5ba45.jpg: 480x640 7 faces, 89.1ms\n",
      "image 17/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\05333b2b99254bb98670bf10f98089d4.jpg: 256x640 11 faces, 78.0ms\n",
      "image 18/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\059a9cbe02bc4f13b0450403d19aa0e5.jpg: 448x640 41 faces, 78.9ms\n",
      "image 19/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\05c56856165f4ad29b1a30fad2cbd5ea.jpg: 512x640 21 faces, 67.5ms\n",
      "image 20/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\062ae06eb73e2ef431109495aee57710.jpg: 480x640 34 faces, 57.8ms\n",
      "image 21/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\06ff315a84af42f58d06201cdcb50a95.jpg: 384x640 103 faces, 57.1ms\n",
      "image 22/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\07933c260bba45b79579e50b6d4c3515.jpg: 384x640 75 faces, 61.0ms\n",
      "image 23/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0884b043075e42be8f0fb6a962777d13.jpg: 448x640 50 faces, 63.1ms\n",
      "image 24/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\08ee03e7b22642ceaa7a80656f55058d.jpg: 480x640 109 faces, 60.5ms\n",
      "image 25/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\092e51bc9c474b529a843ff0e3d260b3.jpg: 480x640 81 faces, 74.5ms\n",
      "image 26/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0972b1681be5484dadb41390fae313de.jpg: 416x640 8 faces, 56.2ms\n",
      "image 27/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0997571e74d34cfca3cf804c83b8a4d9.jpg: 448x640 19 faces, 72.5ms\n",
      "image 28/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0_Parade_Parade_0_213.jpg: 448x640 56 faces, 57.1ms\n",
      "image 29/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0_Parade_Parade_0_226.jpg: 448x640 15 faces, 65.6ms\n",
      "image 30/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0a1c5a0125a24db0b2db37fb12b7971a.jpg: 448x640 2 faces, 56.7ms\n",
      "image 31/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0a9de29a3f734b00b90530d848927204.jpg: 480x640 11 faces, 62.5ms\n",
      "image 32/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0ac4ddf9efdd44fd8befd810a3749290.jpg: 352x640 12 faces, 66.7ms\n",
      "image 33/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0b40bc1ef8cf41d08586a6249d79db23.jpg: 480x640 5 faces, 63.2ms\n",
      "image 34/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0b58320491714162bf1e23b075f5e3de.jpg: 448x640 114 faces, 61.1ms\n",
      "image 35/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0bded59ce9df43258c9efb469aad7a37.jpg: 448x640 59 faces, 58.4ms\n",
      "image 36/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0bdf746fee424ed3b299b427bcb6efdc.jpg: 480x640 108 faces, 55.1ms\n",
      "image 37/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0c2d82c43e344a179c4986b6d254d9a0.jpg: 448x640 11 faces, 54.5ms\n",
      "image 38/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0c2f559eebd9476d82f0c305c7ac6e80.jpg: 384x640 4 faces, 61.8ms\n",
      "image 39/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0ce065f6876e494aa90536855c8223e4.jpg: 384x640 55 faces, 57.7ms\n",
      "image 40/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0d1c47153c38473d9b73f9d7bb9167c6.jpg: 448x640 94 faces, 69.4ms\n",
      "image 41/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0d461deffe324016ab2254c95d1a022c.jpg: 640x448 2 faces, 87.1ms\n",
      "image 42/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0d837dd8fd764cbf98dd135b42193ef1.jpg: 480x640 2 faces, 67.0ms\n",
      "image 43/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0e1757097a784092a9e1a4f8de9fcd22.jpg: 352x640 24 faces, 56.5ms\n",
      "image 44/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0e2132335edd4c2ab675b7362664aecb.jpg: 384x640 6 faces, 74.2ms\n",
      "image 45/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0e44257b8dad495e97144314455849f2.jpg: 384x640 5 faces, 57.0ms\n",
      "image 46/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0e78187e8b4648f1ab8b9bce00e249aa.jpg: 416x640 43 faces, 56.4ms\n",
      "image 47/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0ef3fab5123841a8b72936f78a46cbe3.jpg: 480x640 4 faces, 69.8ms\n",
      "image 48/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0f8104accac84726bd8b8915c6cd5493.jpg: 448x640 18 faces, 60.4ms\n",
      "image 49/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0f9278cab07543da8e67f686d9708aa8.jpg: 448x640 10 faces, 57.1ms\n",
      "image 50/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0fd62230f7684eba9ad51475791d0bbd.jpg: 480x640 41 faces, 67.4ms\n",
      "image 51/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0fe46587fef14dec834a66a71cba87ff.jpg: 448x640 7 faces, 62.7ms\n",
      "image 52/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\0feb3d90a46b426998d98f5e02aefa00.jpg: 448x640 53 faces, 60.7ms\n",
      "image 53/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\1056.jpg: 480x640 6 faces, 59.6ms\n",
      "image 54/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\1174.jpg: 448x640 12 faces, 59.6ms\n",
      "image 55/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\118.jpg: 480x640 45 faces, 51.7ms\n",
      "image 56/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_1.jpg: 448x640 3 faces, 55.4ms\n",
      "image 57/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_1016.jpg: 448x640 7 faces, 56.9ms\n",
      "image 58/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_1027.jpg: 480x640 7 faces, 58.9ms\n",
      "image 59/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_1033.jpg: 640x416 5 faces, 60.1ms\n",
      "image 60/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_105.jpg: 480x640 8 faces, 58.1ms\n",
      "image 61/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_107.jpg: 256x640 26 faces, 43.8ms\n",
      "image 62/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_114.jpg: 640x512 2 faces, 73.2ms\n",
      "image 63/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_116.jpg: 448x640 5 faces, 53.2ms\n",
      "image 64/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_129.jpg: 448x640 4 faces, 47.5ms\n",
      "image 65/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_139.jpg: 512x640 3 faces, 63.3ms\n",
      "image 66/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_14.jpg: 640x640 3 faces, 69.5ms\n",
      "image 67/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_146.jpg: 416x640 8 faces, 53.0ms\n",
      "image 68/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_147.jpg: 448x640 5 faces, 55.6ms\n",
      "image 69/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_150.jpg: 480x640 5 faces, 61.5ms\n",
      "image 70/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_153.jpg: 448x640 8 faces, 61.5ms\n",
      "image 71/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_162.jpg: 480x640 5 faces, 61.3ms\n",
      "image 72/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_164.jpg: 448x640 26 faces, 53.4ms\n",
      "image 73/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_167.jpg: 480x640 9 faces, 60.6ms\n",
      "image 74/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_172.jpg: 448x640 5 faces, 60.7ms\n",
      "image 75/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_18.jpg: 416x640 7 faces, 50.7ms\n",
      "image 76/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_184.jpg: 480x640 2 faces, 56.7ms\n",
      "image 77/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_200.jpg: 416x640 5 faces, 48.5ms\n",
      "image 78/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_203.jpg: 288x640 4 faces, 39.1ms\n",
      "image 79/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_209.jpg: 448x640 14 faces, 54.0ms\n",
      "image 80/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_211.jpg: 448x640 12 faces, 57.1ms\n",
      "image 81/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_212.jpg: 480x640 7 faces, 60.7ms\n",
      "image 82/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_216.jpg: 448x640 15 faces, 61.3ms\n",
      "image 83/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_217.jpg: 448x640 176 faces, 56.2ms\n",
      "image 84/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_219.jpg: 320x640 3 faces, 55.0ms\n",
      "image 85/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_221.jpg: 448x640 11 faces, 60.5ms\n",
      "image 86/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_228.jpg: 480x640 8 faces, 73.1ms\n",
      "image 87/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_229.jpg: 448x640 61 faces, 58.6ms\n",
      "image 88/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_231.jpg: 448x640 11 faces, 54.0ms\n",
      "image 89/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_233.jpg: 640x480 3 faces, 71.3ms\n",
      "image 90/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_238.jpg: 448x640 25 faces, 56.4ms\n",
      "image 91/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_245.jpg: 480x640 16 faces, 65.4ms\n",
      "image 92/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_253.jpg: 480x640 3 faces, 61.3ms\n",
      "image 93/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_256.jpg: 448x640 38 faces, 66.7ms\n",
      "image 94/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_260.jpg: 448x640 4 faces, 56.8ms\n",
      "image 95/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_281.jpg: 288x640 14 faces, 47.6ms\n",
      "image 96/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_284.jpg: 480x640 11 faces, 54.1ms\n",
      "image 97/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_285.jpg: 480x640 28 faces, 54.9ms\n",
      "image 98/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_288.jpg: 448x640 18 faces, 54.7ms\n",
      "image 99/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_289.jpg: 480x640 9 faces, 61.3ms\n",
      "image 100/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_293.jpg: 384x640 6 faces, 60.9ms\n",
      "image 101/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_294.jpg: 480x640 2 faces, 58.3ms\n",
      "image 102/3083 C:\\mywork\\ml\\deepfaceAndEmotion\\source\\11_Meeting_Meeting_11_Meeting_Meeting_11_3.jpg: 448x640 3 faces, 57.1ms\n"
     ]
    }
   ],
   "source": [
    "detect_face('../../deepfaceAndEmotion/source/', 'recognised_emotions.csv', 100)\n",
    "store_with_bounding_box('recognised_emotions.csv','target')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code is to visualize an already inferred data from the csv file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9b3302f2aa4437"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "375acb89c2af8af7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T04:51:08.592081400Z",
     "start_time": "2024-03-18T04:51:08.588851500Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(csv_loc, fileName):\n",
    "    df = pd.read_csv(csv_loc)\n",
    "    filtered = df.loc[df['image_path'].str.contains(fileName)]\n",
    "    list_faces = list(filtered.T.to_dict().values())\n",
    "    image_loc = list_faces[0]['image_path']\n",
    "    image = Image.open(image_loc).convert('RGB')\n",
    "    show_bbox_with_emotion(image, list_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#visualize('recognised_emotions.csv','0884b043075e42be8f0fb6a962777d13')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T04:51:14.386972300Z",
     "start_time": "2024-03-18T04:51:10.845845400Z"
    }
   },
   "id": "2da58a39b1f6b928"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a44bf12ed4edea4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
